{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a4d2c4-93f6-4124-8e94-688797d59729",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RAIL SOMPZ Estimator Demo\n",
    "\n",
    "Authors: Sam Schmidt, Justin Myles\n",
    "\n",
    "Last successfully run: June 12, 2024\n",
    "\n",
    "This demo notebook follows the informer demo for the `rail_sompz` method, `rail_sompz_inform_demo.ipynb`, and uses the model file `DEMO_romandesc_model.pkl` that is created in that notebook.  So, you will need to run that notebook and train a model consisting of the wide and deep SOMs before this one in order to run the estimate stage and produce tomographic bin estimates.\n",
    "\n",
    "The estimate method uses the two SOMs trained in the inform method in order to construct tomographic bin estimates.  The algorithm works by determining weights for a spectroscopic dataset based on a wider \"deep\" dataset relative to a (usually larger) wide dataset.  See [Myles, Alarcon et al. 2021](https://arxiv.org/pdf/2012.08566) and references in [Campos et al. 2023](https://github.com/AndresaCampos/sompz_y6) for more details on the method.\n",
    "\n",
    "We'll start with our usual imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af1c10-6fce-4276-b86f-6fe57cf80ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from rail.core.utils import RAILDIR\n",
    "from rail.core import common_params\n",
    "import tables_io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import astropy.io.fits as fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7296324b-29a4-4227-9532-b290e4a94cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rail.estimation.algos.sompz import SOMPZInformer\n",
    "from rail.estimation.algos.sompz import SOMPZEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4597943c-fd10-4114-8160-ad4d590ca7e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "The SOMPZ method usually leverages a \"deep\" dataset with extra bands (often in the near-infrared), where the extra photometric information in the extended wavelength coverage enables a magnitudes/colors -> redshift mapping with less degeneracies than when using optical colors along.  For this demo, we will use data from the Rubin-Roman simulation [Citation needed!], which does contain simluated photometry for both the Rubin optical `ugrizy` bands as well as the Roman `JHFK` bands.  We have included a command-line tool in RAIL that will grab several data files that we will use in this demo.  If you ran the informer demo they are already in place and you can ignore the following cell, if you moved/deleted files, or just copied the model from the informer stage and still need the data, then uncomment the lines in the cell below to grab the data files, move, and untar them in the appropriate location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4dc6fe-719e-40e6-990a-9b0e832c8c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl -O https://portal.nersc.gov/cfs/lsst/PZ/roman_desc_demo_data.tar.gz\n",
    "#!mkdir DEMODATA\n",
    "#!tar -xzvf roman_desc_demo_data.tar.gz\n",
    "#!mv romandesc*.hdf5 DEMODATA/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e46b10b-8cca-41fd-9044-ac51ac9f6754",
   "metadata": {},
   "source": [
    "Now, let's load the three files that we will use into memory.  The \"spec\" file contains the galaxies with spectroscopic redshifts, these are usually a subset of the \"deep\" data (and that is the case here).  The \"deep\" data contains both optical and NIR bands, in this case `ugrizyJHF`.  And the \"wide\" data contains only `ugrizy` photometry.  The code will determine the cell occupation of the spec sample, determine weights via the deep sample, and attempt to create tomographic bin estimates for the sample based on SOM cell occupation.\n",
    "\n",
    "\n",
    "There are two sets of files included in the Rubin-Roman download, one set that is a factor of 20 larger than the other.  For a quick demo, use the file names for `specfile`, `deepfile`, and `widefile` as-is below, for a more robust estimate with more training and estimation data, switch to the larger files by uncommenting and commenting the file names below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231a13e-260f-4271-93ec-a893fb876268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf95e06-d6a6-4ac9-9260-c5271ed6f40c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582c84a-eb2c-43df-bfcd-a92992d745b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "## Larger files to use if you want slightly more robust demo (will take longer to run)\n",
    "#specfile = \"./DEMODATA/romandesc_spec_data_37k_noinf.hdf5\"\n",
    "#deepfile = \"./DEMODATA/romandesc_deep_data_75k_noinf.hdf5\"\n",
    "#widefile = \"./DEMODATA/romandesc_wide_data_100k_noinf.hdf5\"\n",
    "## smaller files for a quick demo, swap which lines are commented if you don't mind some extra run time\n",
    "specfile = \"./DEMODATA/romandesc_spec_data_18c_noinf.hdf5\"\n",
    "deepfile = \"./DEMODATA/romandesc_deep_data_37c_noinf.hdf5\"\n",
    "widefile = \"./DEMODATA/romandesc_wide_data_50c_noinf.hdf5\"\n",
    "\n",
    "spec_data = DS.read_file(\"spec_data\", TableHandle, specfile)\n",
    "balrog_data = DS.read_file(\"deep_data\", TableHandle, deepfile)\n",
    "wide_data = DS.read_file(\"wide_data\", TableHandle, widefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae2cae-6c44-4fc2-8083-eb93440add24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1b7bcca-8e47-461a-81cc-cf07e6bb9293",
   "metadata": {},
   "source": [
    "We need to set up several parameters used by the estimate stage, namely the names of the inputs (for both deep and wide), the names of the input errors (again for both deep and wide), the zero points.  In our dataset, the bands are simply called e.g. `u`, and `J`, and the errors `u_err` and `J_err`.  The \"deep\" SOM we will use both optical and NIR bands, for the wide data we will only use ugrizy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fce31d-31b9-46d5-adff-e7c1056ec822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bands = ['u','g','r','i','z','y','J','H', 'F']\n",
    "#bands = ['u','g','r','i','z','y']\n",
    "\n",
    "deepbands = []\n",
    "deeperrs = []\n",
    "zeropts = []\n",
    "for band in bands:\n",
    "    deepbands.append(f'{band}')\n",
    "    deeperrs.append(f'{band}_err')\n",
    "    zeropts.append(30.)\n",
    "\n",
    "widebands = []\n",
    "wideerrs = []  \n",
    "for band in bands[:6]:\n",
    "    widebands.append(f'{band}')\n",
    "    wideerrs.append(f'{band}_err')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a311fd5-7554-497c-965e-62136809fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(widebands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f45556-b6dc-4907-bd1b-a3e94e9c3879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3804d2e-3355-4ed6-8979-6ad0f4fa19dc",
   "metadata": {},
   "source": [
    "There are many configuration parameters that we can access to control the behavior of the estimate stage, these are described below.  Any values not specified will take on their default values as set in the parameter config that is located in the class:\n",
    "\n",
    "`bin_edges`: the list of edges of tomo bins<br>\n",
    "`zbins_min`: minimum redshift for output grid<br>\n",
    "`zbins_max`: maximum redshift for output grid<br>\n",
    "`zbins_dz`: delta z for defining output grid<br>\n",
    "`spec_groupname`: hdf5_groupname for spec_data<br>\n",
    "`balrog_groupname`: hdf5_groupname for balrog_data<br>\n",
    "`wide_groupname`: hdf5_groupname for wide_data<br>\n",
    "`specz_name`: column name for true redshift in specz sample<br>\n",
    "`inputs_deep`: list of the names of columns to be used as inputs for deep data<br>\n",
    "`input_errs_deep`: list of the names of columns containing errors on inputs for deep data<br>\n",
    "`inputs_wide`: list of the names of columns to be used as inputs for wide data<br>\n",
    "`input_errs_wide`: list of the names of columns containing errors on inputs for wide data<br>\n",
    "`zero_points_deep`: zero points for converting mags to fluxes for deep data, if needed<br>\n",
    "`zero_points_wide`: zero points for converting mags to fluxes for wide data, if needed<br>\n",
    "`som_shape_deep`: shape for the deep som, must be a 2-element tuple<br>\n",
    "`som_shape_wide`: shape for the wide som, must be a 2-element tuple<br>\n",
    "`som_minerror_deep`: floor placed on observational error on each feature in deep som<br>\n",
    "`som_minerror_wide`: floor placed on observational error on each feature in wide som<br>\n",
    "`som_wrap_deep`: flag to set whether the deep SOM has periodic boundary conditions<br>\n",
    "`som_wrap_wide`: flag to set whether the wide SOM has periodic boundary conditions<br>\n",
    "`som_take_log_deep`: flag to set whether to take log of inputs (i.e. for fluxes) for deep som<br>\n",
    "`som_take_log_wide`: flag to set whether to take log of inputs (i.e. for fluxes) for wide som<br>\n",
    "`convert_to_flux_deep`: flag for whether to convert input columns to fluxes for deep data, set to true if inputs are mags and to False if inputs are already fluxes<br>\n",
    "`convert_to_flux_wide`=Param(bool, False, msg=\"flag for whether to convert input columns to fluxes for wide data<br>\n",
    "`set_threshold_deep`: flag for whether to replace values below a threshold with a set number<br>\n",
    "`thresh_val_deep`: threshold value for set_threshold for deep data<br>\n",
    "`set_threshold_wide`: flag for whether to replace values below a threshold with a set number<br>\n",
    "`thresh_val_wide`: threshold value for set_threshold for wide data<br>\n",
    "`debug`: boolean reducing dataset size for quick debugging, will take only the first 200 rows of each of the spec, deep, and wide files so things run quicker<br>\n",
    "\n",
    "\n",
    "Let's define a dictionary with the config parameters that we need to set in order to have things work with the Roman-DESC data.  We will also set a custom set of `bin_edges` with six values that will produce five tomographic bins where the SOM will do its best to assign galaxies to the bins bounded by each of the bin edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909db34c-8219-4cb2-9dd0-468a67df2a12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tomo_binedges = [0.0, 0.5, 0.8, 1.1, 1.5, 3.0]\n",
    "som_params = dict(inputs_deep=deepbands, input_errs_deep=deeperrs, \n",
    "                  inputs_wide=widebands, input_errs_wide=wideerrs,  \n",
    "                  zero_points_deep=zeropts, zero_points_wide=zeropts[:6],\n",
    "                  convert_to_flux_deep=True, convert_to_flux_wide=True, \n",
    "                  set_threshold_deep=True, thresh_val_deep=1.e-5, \n",
    "                  som_shape_wide=(25, 25), som_minerror_wide=0.005,\n",
    "                  som_take_log_wide=False, som_wrap_wide=False,\n",
    "                  zbins_min=0.0, zbins_max=5.0, zbins_dz=0.05,\n",
    "                  spec_groupname='', balrog_groupname='', wide_groupname='',\n",
    "                  bin_edges=tomo_binedges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402500c-2c36-4126-b0a3-46e8327c9fcc",
   "metadata": {},
   "source": [
    "Now we will set up the stage that will run the estimator, we will grab the model file that we trained in the informer demo run previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4bd7b9-b23e-4f30-bc6c-d553c63e5bac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rd_som_estimate = SOMPZEstimator.make_stage(name=\"som_estimator\", \n",
    "                                         model=\"DEMO_romandesc_model.pkl\", \n",
    "                                         **som_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7decf1-ccea-4865-b905-ad4abf1b17e9",
   "metadata": {},
   "source": [
    "Now, let's run the estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f21520f-ed97-41d5-a32b-1ce7be1759f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rd_som_estimate.estimate(spec_data,\n",
    "                         balrog_data,\n",
    "                         wide_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20624344-820e-479e-8f26-1c1c25aef766",
   "metadata": {},
   "source": [
    "The five tomographic bin estimates are stored in an output file with the name that we assigned to the SOMPZEstimator stage, prepended with an `nz_`, let's read in that file and display our tomographic bin estimates, along with the bin edges that we set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da39595a-c818-4011-b787-f8e4663d1bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206a11e-afb4-44a9-a216-811ac6e6c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = qp.read(\"nz_som_estimator.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d6d73-ef96-41c2-9555-fd309d0fdd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "binedges = [0.0, 0.5, 0.8, 1.1, 1.5, 3.0]\n",
    "fig, axs = plt.subplots(1,1, figsize=(10,6))\n",
    "cols=['r','purple','b','orange','k']\n",
    "for i, col in enumerate(cols):\n",
    "    ens[i].plot_native(axes=axs, color=col)\n",
    "    axs.axvline(binedges[i+1], color=col, ls='--', lw=0.9)\n",
    "axs.set_xlabel(\"redshift\", fontsize=14)\n",
    "axs.set_ylabel(\"N(z)\", fontsize=14)\n",
    "axs.set_xlim(0,3.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105fc716-7f33-4b07-ab71-c73bb50bf007",
   "metadata": {},
   "source": [
    "Looks very good! Nice separation, without many bumps outside of the bin due to degeneracies.  The addition of the near-infrared bands can break many of the degeneracies where the Lyman and Balmer breaks are confused for each other.  This demonstrates the power of this technique, and how using NIR (or any other additional band information) can help us in determining our redshift distributions.\n",
    "\n",
    "We can also try breaking up our wide sample into tomo bins based on the \"best\" cell assignment and compare our estimated redshift distribution to the histogram of wide sample redshifts in that bin.  The estimator will spit out a file named `tomo_bin_mask_wide_data_[name of stage].hdf5`, in this case `tomo_bin_mask_wide_data_som_estimator.hdf5`.  That file contains a dictionary with two keys, `bin` which is an integer corresponding to which tomographic bin each galaxy is assigned to, and `weight`, a weight (in this case they are all 1.0) for each galaxy within the bin.  We can use this data to compare our tomographic bin estimate to the true redshift distributions for our bin samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa9b169-e8ae-46cd-8672-e54a50ef61a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tomo_mask_file = \"tomo_bin_mask_wide_data_som_estimator.hdf5\"\n",
    "tomomaskdata = tables_io.read(tomo_mask_file)\n",
    "tomo_mask = tomomaskdata['bin']\n",
    "tomo_weight = tomomaskdata['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a56ce-1b5e-4c6f-b20f-a1444961e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = wide_data()['redshift']\n",
    "nbins = len(tomo_binedges)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e94b4a-c5ff-4304-92c0-66424c25ebc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5aa9d08-0c98-4a31-bba1-e8b294b689e5",
   "metadata": {},
   "source": [
    "Let's make some comparison plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b57c0-470a-46d6-a1eb-f7004b7dabd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "histedges = np.linspace(-.05,5.05,208)\n",
    "fig, axs = plt.subplots(5, 1, figsize=(10,12))\n",
    "for i in range(nbins):\n",
    "    binmask = (tomo_mask == i)\n",
    "    binsz = sz[binmask]\n",
    "    axs[i].hist(binsz, bins=histedges, color='k', alpha=0.4, density=True, label='true redshift hist')\n",
    "    ens[i].plot_native(axes=axs[i], color='r', label='SOMPZ tomo estimate')\n",
    "    axs[i].set_ylabel(\"N(z)\", fontsize=12)\n",
    "    axs[i].set_xlim(-.005,3.15)\n",
    "axs[4].set_xlabel(\"redshift\", fontsize=12)\n",
    "axs[0].legend(loc='upper right', fontsize=14)\n",
    "#plt.savefig(\"tomo_bins_truth_compare.jpg\", format=\"jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d2c4e-c3eb-4279-813a-ee2e42dc6dce",
   "metadata": {},
   "source": [
    "We see very good agreement between the true distributions and our SOMPZ estimates, including the small outlier bumps in the highest redshift bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac68a632-9054-4137-8291-201b0bab48e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
