{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7959e629-7461-41e7-b0ec-b158f5c5b30b",
   "metadata": {},
   "source": [
    "# Quick and dirty test of rough draft of SOMPZInformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9463120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# usual imports\n",
    "import os\n",
    "import numpy as np\n",
    "from rail.core.utils import RAILDIR\n",
    "#from rail.estimation.algos.sompz_version.utils import RAIL_SOMPZ_DIR\n",
    "#from rail.pipelines.estimation.inform_all import InformPipeline\n",
    "from rail.core import common_params\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ddec78-453c-432d-8613-67ce5a9fe959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e5a23-c2cf-40df-ab43-ca26a4fd78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.estimation.algos.sompz import SOMPZInformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ba7eb-9b07-4284-8885-9ca0aa6b0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e01f0ea-3687-4725-bc26-9d65d3100482",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249fa375-a847-4482-9a68-763f3cf4849d",
   "metadata": {},
   "source": [
    "read in some test data for the \"wide\" som, it's just 20,000 mock ugrizy magnitudes and errors from cosmodc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1bb980-447f-461c-bbe3-72e57cb9e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.core.utils import find_rail_file\n",
    "#trainFile = find_rail_file('examples_data/testdata/test_dc2_training_9816.hdf5')\n",
    "testFile = find_rail_file('examples_data/testdata/test_dc2_validation_9816.hdf5')\n",
    "#deep_data = DS.read_file(\"training_data\", TableHandle, trainFile)\n",
    "wide_data = DS.read_file(\"input_wide_data\", TableHandle, testFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ada546-1d0e-4e61-b24d-3e87f6f65cf9",
   "metadata": {},
   "source": [
    "I have copied the file that Justin made to this directory and will read that fits file in to test the \"deep\" som.  If you have the file somewhere else, then update the \"hsc_file\" path in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d6d0d-50d1-4b38-b5c9-a6e2cc0697a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsc_file = \"hsc_deep_incl_nir_incl_specz_TEST_ONLY_NO_SCIENCE_2023-10-18.fits\"\n",
    "deep_data = DS.read_file(\"training_data\", TableHandle, hsc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335dce95-6ca3-49bb-ac83-b093ffc404a8",
   "metadata": {},
   "source": [
    "To speed things up a bit, I'm going to grab 10% of the data and actually use that.  It should work with the big data, but this will be faster to train up the som for a quick demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9e9a3d-ad2b-42ae-973d-172b0cb782f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = deep_data()[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34140f55-6c45-46c6-a9a9-0d823e1139ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_data = DS.add_data(\"smaller_data\", subset, TableHandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e4aa10-4107-4dce-9b68-ee4a9a73f2b9",
   "metadata": {},
   "source": [
    "create a few lists of names that we'll need for the names of the input columns that we'll used in the SOM, along with their errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930bd934-ed4b-4c83-9b63-85d07bea735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['u','g','r','i','z','J','H', 'K']\n",
    "deepbands = []\n",
    "deeperrs = []\n",
    "zeropts = []\n",
    "for band in bands:\n",
    "    deepbands.append(f'flux_DES_DEEP_{band}')\n",
    "    deeperrs.append(f'flux_err_DES_DEEP_{band}')\n",
    "    zeropts.append(30.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd96dee-0dc6-4748-9357-02f9b8360b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepbands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2796070e-548f-42f0-a1ab-719fa13e4733",
   "metadata": {},
   "source": [
    "make a dictionary of the parameters that we'll feed into the informer for the deep som.  Because we're using HSC data we need the non-default names fo the input columns (`inputs_deep`) and the errors (`input_errs_deep`).  We'll feed in a list for the zero points (`zero_points`) as well, as eventually we'll want to add a check to make sure all three of those have the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a722208-6dbf-469c-921d-969ed78aa5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_params = dict(inputs_deep=deepbands, input_errs_deep=deeperrs, zero_points_deep=zeropts, \n",
    "                  convert_to_flux=False, set_threshold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0560e-2891-47b7-a24b-a6311dc08056",
   "metadata": {},
   "source": [
    "deep_groupname and hdf5_groupname (along with an unused wide_groupname) have to do with hdf5 groups and how we read the data, hdf5_groupname is not used in this stage, but it is expected by the parent class, so I'm setting it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47abc0e5-1408-4bf7-ba4f-df6994285a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_inform = SOMPZInformer.make_stage(name=\"som_informer\", deep_groupname='', hdf5_groupname='',\n",
    "                                      model=\"TEST_HSC_DC2_model.pkl\", **som_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22a7222-68e2-422a-b71a-f7fdfbb13a27",
   "metadata": {},
   "source": [
    "Now, run the informer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c18fbfe-a72d-4c1c-86bd-1e2462686cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_inform.inform(smaller_data, wide_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d22853e-ae95-4977-b1a9-08b86c50382c",
   "metadata": {},
   "source": [
    "Let's look at the results by reading the model we just wrote out, `TEST_HSC_DC2_model.pkl` and looking at what it contains.  It should be a dictionary that contains two soms: `deep_som` and `wide_som`, along with the `deep_columns`, `wide_columns`, `deep_err_columns`, and `wide_err_columns` lists.  I think we'll want to store these as they basically define the ordering of the columns and errors, and we'll want that the same for data that we pass in (if we pass in more data?  I need to look at how the estimate stage works...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a40ca-50d4-4045-93a4-e28564e75817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526df18a-a12e-4d75-b832-4ad270909b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"TEST_HSC_DC2_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ad484-9c9d-4d40-8f20-29f2ee3a101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7357e9a4-ffc8-4ad5-98e9-1f03d5de4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rail.estimation.algos.som as SOMFUNCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a64836-a4a9-4e8e-8c37-d80f681eb699",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOMFUNCS.somDomainColorsnok(model['deep_som'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e1ae8-19cc-42c4-b400-6bac5ab444b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOMFUNCS.somDomainColors(model['deep_som'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad36ec-85e9-44b7-a4b2-fef371f63130",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOMFUNCS.somDomainColorsnok(model['wide_som'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4920cf5-6d83-40a5-bad6-26f2a9b2d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOMFUNCS.somPlot2d(model['deep_som'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f87d5a-bc55-4920-944a-af7389126454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644d7d8-1f47-4885-9db4-2e49f61bb718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
